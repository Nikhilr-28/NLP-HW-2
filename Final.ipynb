{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "070khH_NBax8"
      },
      "source": [
        "# Libraries which will be used to implement this NLP HW-2\n",
        "1. As we have used a dataset (.TSV), to read from and it and access the contents in it, we make use of pandas as pd\n",
        "2. We make use of numpy for our mathematical operations\n",
        "3. We make use of re for cleaning the text (from the used dataset), as a regular expression\n",
        "4. We make use of nltk (a NLP tool) for stop words removal, tokenization, etc..\n",
        "5. gensim library is used to generate two sets of Word2Vec features\n",
        "   KeyedVectors is used to load the Google News Word2Vec model\n",
        "6. sklearn is primarily used for feature extraction, data splitting, evaluation and baseline models.\n",
        "7. PyTorch is a Deep Learning model construction, used for training and optimization, data handlin, and GPU acceleration (Sadly, could not make GPU work)   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNlt59iQBax-",
        "outputId": "519ebb04-4dc1-4cbf-89d8-8952b88b7147"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import random\n",
        "import gzip\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "import gensim\n",
        "import gensim.downloader as api\n",
        "from gensim.models import Word2Vec, KeyedVectors\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.linear_model import Perceptron\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBHMi1WTBax_"
      },
      "source": [
        "# DATASET GENERATION:     \n",
        "STEP 1 OF HW-2:\n",
        "\n",
        "We are using the same dataset \"amazon_reviews_us_Office_Products_v1_00.tsv.gz\" that we used in assignment 1 here as well.\n",
        "We will now take this dataset (given) and read it as a dataframe (df var in code) and keep the necessary columns only.\n",
        "\n",
        "The var. \"FILE_PATH\" is the path to the dataset with which we manipulate necessary changes\n",
        "Using \"df_full\", we do the above mentioned changes such as keeping the necessary column(s), review the text and ratings.\n",
        "\n",
        "Next, we make sure that \"Rating\" is pure numeric and drop any rows with NaN not a (number)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "cVyVYSU7BayA"
      },
      "outputs": [],
      "source": [
        "FILE_PATH = \"/content/amazon_reviews_us_Office_Products_v1_00.tsv.gz\" #/content/amazon_reviews_us_Office_Products_v1_00.tsv.gz\n",
        "\n",
        "\n",
        "df_full = pd.read_csv(\n",
        "    FILE_PATH,\n",
        "    sep='\\t',\n",
        "    compression='gzip',\n",
        "    on_bad_lines='skip',\n",
        "    low_memory=False\n",
        ")\n",
        "\n",
        "\n",
        "df_full = df_full[['review_body', 'star_rating']].copy()\n",
        "df_full.columns = ['Review', 'Rating']\n",
        "\n",
        "df_full.dropna(subset=['Review', 'Rating'], inplace=True)\n",
        "df_full['Rating'] = pd.to_numeric(df_full['Rating'], errors='coerce')\n",
        "df_full.dropna(subset=['Rating'], inplace=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNvbb-u9BayA"
      },
      "source": [
        "We start off with \"print(df_full.shape)\" which prints the original dataframe. With this, we can identify the number of rows and columns before sampling.\n",
        "\n",
        "Then, we loop through each rating (starting from 1 till 5), and calculate how many rows have what rating, with \"rating_count\"\n",
        "\n",
        "We then print the count to see output and used for debugging as well.\n",
        "\n",
        "The 2nd for loop iterates over every rating again. This then filters the dataframe to keep only rows of the current rating values and then we print it.\n",
        "And then, we randomly take 50,000 samples (rows). This ensures the criteria specified in the assignment file to use exactly 50,000 reviews.\n",
        "\n",
        "Finally, we concatenate all sampled subsets into a new dataframe. As concatenations can cause discontinous index, the index is reset. The final dataframe is then printed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igi8P9EABayB",
        "outputId": "3777568f-5072-471d-9dc7-f47353e94ce7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2640080, 2)\n",
            "Rating 1 has 306967 rows\n",
            "Rating 2 has 138381 rows\n",
            "Rating 3 has 193680 rows\n",
            "Rating 4 has 418348 rows\n",
            "Rating 5 has 1582704 rows\n",
            "temp_df rating=1 shape: (306967, 2)\n",
            "temp_df rating=2 shape: (138381, 2)\n",
            "temp_df rating=3 shape: (193680, 2)\n",
            "temp_df rating=4 shape: (418348, 2)\n",
            "temp_df rating=5 shape: (1582704, 2)\n",
            "df_balanced shape: (250000, 2)\n"
          ]
        }
      ],
      "source": [
        "print(df_full.shape)\n",
        "\n",
        "for rating_value in [1, 2, 3, 4, 5]:\n",
        "    rating_count = (df_full['Rating'] == rating_value).sum()\n",
        "    print(f\"Rating {rating_value} has {rating_count} rows\")\n",
        "\n",
        "dfs = []\n",
        "\n",
        "for rating_value in [1, 2, 3, 4, 5]:\n",
        "    temp_df = df_full[df_full['Rating'] == rating_value]\n",
        "    # Print shape of temp_df for debugging\n",
        "    print(f\"temp_df rating={rating_value} shape:\", temp_df.shape)\n",
        "\n",
        "    temp_df_sampled = temp_df.sample(n=50000, random_state=42)\n",
        "    dfs.append(temp_df_sampled)\n",
        "\n",
        "df_balanced = pd.concat(dfs, axis=0).reset_index(drop=True)\n",
        "print(\"df_balanced shape:\", df_balanced.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYFR_qZ-BayB"
      },
      "source": [
        "We now define a function \"map_rating_to_class\" that takes numeric rating 'r' and maps it according to specified fields, being positive(4 or 5), neutral(3) and negative(1 or 2).\n",
        "We then apply the mapping function to the rating column, creating a new column \"sentiment\" with values 1,2,3."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvrO3oqZBayB",
        "outputId": "030885e1-72c9-47d4-b02f-ee77e57b2d1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Value counts for Sentiment:\n",
            "Sentiment\n",
            "2    100000\n",
            "1    100000\n",
            "3     50000\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "def map_rating_to_class(r):\n",
        "    if r > 3:\n",
        "        return 1  # Positive\n",
        "    elif r < 3:\n",
        "        return 2  # Negative\n",
        "    else:\n",
        "        return 3  # Neutral\n",
        "\n",
        "df_balanced['Sentiment'] = df_balanced['Rating'].apply(map_rating_to_class)\n",
        "\n",
        "print(\"Value counts for Sentiment:\")\n",
        "print(df_balanced['Sentiment'].value_counts())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gg54489KBayB"
      },
      "source": [
        "As mentioned in the pdf, we now split the dataset into training (80%) and testing (20%).\n",
        "We make use of \"stratify=df_balanced['Sentiment']\" to preserve the class distribution proportionally in both train and test sets.\n",
        "We then print the training and testing dataframes to confirm whether they match the required specifications."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_IdYOesQBayC",
        "outputId": "cb02ecc3-d034-45c3-acab-e70a1c8dac7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train shape: (200000, 3)\n",
            "Test shape : (50000, 3)\n",
            "Sentiment\n",
            "1    80000\n",
            "2    80000\n",
            "3    40000\n",
            "Name: count, dtype: int64\n",
            "Sentiment\n",
            "1    20000\n",
            "2    20000\n",
            "3    10000\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "train_df, test_df = train_test_split(\n",
        "    df_balanced,\n",
        "    test_size=0.2,\n",
        "    stratify=df_balanced['Sentiment'],\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(\"Train shape:\", train_df.shape)\n",
        "print(\"Test shape :\", test_df.shape)\n",
        "\n",
        "# Check distribution of sentiment in each set\n",
        "print(train_df['Sentiment'].value_counts())\n",
        "print(test_df['Sentiment'].value_counts())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Sj0wrWmBayC"
      },
      "source": [
        "# WORD EMBEDDING          \n",
        "STEP 2 OF HW-2:PART-A\n",
        "To try out the api way of using the word2vec model, we have made use of the api command from the \"helpful tutorial given in the HW-2 pdf\".\n",
        "We have printed before and after for debugging purposes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MugSuK_-BayC",
        "outputId": "03c48de5-6bc3-4428-eb6f-ecde9166907b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading 'word2vec-google-news-300'\n",
            "Model loaded successfully!\n"
          ]
        }
      ],
      "source": [
        "print(\"Loading 'word2vec-google-news-300'\")\n",
        "wv = api.load('word2vec-google-news-300')\n",
        "print(\"Model loaded successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgpqPALHBayC"
      },
      "source": [
        "From the pdf, we can see that we need to test out the dataset and validate the semantic similarities.   \n",
        " The following code does exactly that. We take the sample example from the pdf and one of our own, to compare within the top 5 contenders and thier metric values. Hence, we know that the code works! With this, we complete PART-A of our step 2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZj4q-XmBayD",
        "outputId": "b5a58a08-2857-4ff5-f5a8-3bdd01829b34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Analogy: king - man + woman = ? \n",
            "queen: 0.7118\n",
            "monarch: 0.6190\n",
            "princess: 0.5902\n",
            "crown_prince: 0.5499\n",
            "prince: 0.5377\n",
            "\n",
            "Similarity between 'excellent' and 'outstanding': 0.5567\n",
            "\n",
            "Most similar words to 'excellent':\n",
            "terrific: 0.7410\n",
            "superb: 0.7063\n",
            "exceptional: 0.6815\n",
            "fantastic: 0.6803\n",
            "good: 0.6443\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nAnalogy: king - man + woman = ? \")\n",
        "result_analogy = wv.most_similar(positive=['king', 'woman'], negative=['man'], topn=5)\n",
        "for word, sim in result_analogy:\n",
        "    print(f\"{word}: {sim:.4f}\")\n",
        "\n",
        "sim_score = wv.similarity('excellent', 'outstanding')\n",
        "print(f\"\\nSimilarity between 'excellent' and 'outstanding': {sim_score:.4f}\")\n",
        "\n",
        "most_similar_excellent = wv.most_similar('excellent', topn=5)\n",
        "print(\"\\nMost similar words to 'excellent':\")\n",
        "for word, sim in most_similar_excellent:\n",
        "    print(f\"{word}: {sim:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KrN6XbrcBayD"
      },
      "source": [
        "# The next 2 code blocks are given a part of Step-3 in the pdf. But, improved scores were observed when used in between STEP-2 PART (A) AND PART (B).      \n",
        "\n",
        "This first code block does the Data cleaning (exact same used in HW-1 as mentioned in pdf)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8xAH-4mBayD",
        "outputId": "813dcf52-261e-4576-9e74-79b4f6711f76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average length (in characters) before cleaning: 341.193312\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-c636221de1a1>:11: MarkupResemblesLocatorWarning: The input passed in on this line looks more like a URL than HTML or XML.\n",
            "\n",
            "If you meant to use Beautiful Soup to parse the web page found at a certain URL, then something has gone wrong. You should use an Python package like 'requests' to fetch the content behind the URL. Once you have the content as a string, you can feed that string into Beautiful Soup.\n",
            "\n",
            "However, if you want to parse some data that happens to look like a URL, then nothing has gone wrong: you are using Beautiful Soup correctly, and this warning is spurious and can be filtered. To make this warning go away, run this code before calling the BeautifulSoup constructor:\n",
            "\n",
            "    from bs4 import MarkupResemblesLocatorWarning\n",
            "    import warnings\n",
            "\n",
            "    warnings.filterwarnings(\"ignore\", category=MarkupResemblesLocatorWarning)\n",
            "    \n",
            "  text_no_html = BeautifulSoup(text, \"html.parser\").get_text(separator=\" \")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average length (in characters) after cleaning: 323.726712\n"
          ]
        }
      ],
      "source": [
        "df_balanced.dropna(subset=['Review'], inplace=True)\n",
        "df_balanced['Review'] = df_balanced['Review'].astype(str)\n",
        "\n",
        "avg_length_before_cleaning = df_balanced['Review'].apply(len).mean()\n",
        "print(\"Average length (in characters) before cleaning:\", avg_length_before_cleaning)\n",
        "\n",
        "df_balanced['Review'] = df_balanced['Review'].str.lower()\n",
        "\n",
        "def remove_html_and_urls(text):\n",
        "    # Remove HTML tags using BeautifulSoup\n",
        "    text_no_html = BeautifulSoup(text, \"html.parser\").get_text(separator=\" \")\n",
        "\n",
        "    text_no_url = re.sub(r'(https?://\\S+|www\\.\\S+)', '', text_no_html)\n",
        "\n",
        "    return text_no_url\n",
        "\n",
        "df_balanced['Review'] = df_balanced['Review'].apply(remove_html_and_urls)\n",
        "\n",
        "df_balanced['Review'] = df_balanced['Review'].str.replace('[^a-z]', ' ', regex=True)\n",
        "\n",
        "df_balanced['Review'] = df_balanced['Review'].str.split().str.join(' ')\n",
        "\n",
        "#did my best to add as much as possible\n",
        "contractions_dict = {\n",
        "    \"won't\": \"will not\",\n",
        "    \"can't\": \"cannot\",\n",
        "    \"don't\": \"do not\",\n",
        "    \"didn't\": \"did not\",\n",
        "    \"i'm\": \"i am\",\n",
        "    \"it's\": \"it is\",\n",
        "    \"he's\": \"he is\",\n",
        "    \"she's\": \"she is\",\n",
        "    \"that's\": \"that is\",\n",
        "    \"aren't\": \"are not\",\n",
        "    \"weren't\": \"were not\",\n",
        "    \"haven't\": \"have not\",\n",
        "    \"hasn't\": \"has not\",\n",
        "    \"shouldn't\": \"should not\",\n",
        "    \"wouldn't\": \"would not\",\n",
        "    \"couldn't\": \"could not\",\n",
        "    \"isn't\": \"is not\",\n",
        "    \"what's\": \"what is\",\n",
        "    \"where's\": \"where is\",\n",
        "    \"who's\": \"who is\",\n",
        "    \"you'd\": \"you would\",\n",
        "    \"you'll\": \"you will\",\n",
        "    \"you're\": \"you are\",\n",
        "    \"they're\": \"they are\",\n",
        "    \"they've\": \"they have\",\n",
        "    \"we're\": \"we are\",\n",
        "    \"we've\": \"we have\",\n",
        "    \"there's\": \"there is\"\n",
        "}\n",
        "\n",
        "contractions_pattern = re.compile(r'\\b(' + '|'.join(contractions_dict.keys()) + r')\\b')\n",
        "\n",
        "def expand_contractions(text, pattern=contractions_pattern):\n",
        "    def replace(match):\n",
        "        return contractions_dict[match.group(0)]\n",
        "    return pattern.sub(replace, text)\n",
        "\n",
        "df_balanced['Review'] = df_balanced['Review'].apply(expand_contractions)\n",
        "\n",
        "avg_length_after_cleaning = df_balanced['Review'].apply(len).mean()\n",
        "print(\"Average length (in characters) after cleaning:\", avg_length_after_cleaning)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfVRqpyzBayD"
      },
      "source": [
        "This code block does the pre-processing (Again, as explained in the pdf, this is the code used in HW-1)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OOPeut70BayD",
        "outputId": "95c4f8e0-c4d4-4391-e599-b9251f24b262"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SAMPLE REVIEWS BEFORE PREPROCESSING:\n",
            "Review 38683:\n",
            "light didn t work so i tried to replace the battery and the entire pen basically fell apart in my hands this is the biggest piece of crap i ve ever bought even if it had been working the pieces are about as cheap as cheap can get yet still costs for some reason also the first time i have to return an order on amazon in over purchases\n",
            "--------------------------------------------------------------------------------\n",
            "Review 64939:\n",
            "let me say up front that i m going to try to upload a picture of my badge holder for you all to look at if it s there great if not then i ll just say that after only three months of routine use the badge holder s developed substantial cracks at its central stress point and is no longer functional it is clear to me that the design itself is fundamentally flawed the routine removing and inserting of just one card approximately six times a day over the course of a five day week should not result in product failure in less than three months the badge holder i had before this one lasted two years it s a shame because i think there is a significant population out there that would be willing to shell out the extra cash for a durable dependable product and if this company just upgraded the quality of their plastic then they just might have a winner on their hands i can t recommend this product because it broke much too quickly after non abusive routine use i did give it two stars however because it worked great when it worked\n",
            "--------------------------------------------------------------------------------\n",
            "Review 3954:\n",
            "the printer will not print in any color if just one of the ink cartridges are out i ve had terrible problems with the printing skipping around you can t even read what is being read i learned that if you do the maintenence and clean the heads printer has option and does it by itself after option is selected that will clear up however you have to clean the head more than once just today i went to office max and spent on ink box of multi black because my black was out the printer would not print after getting home i cleaned the heads about times which still did not completely fix the problem with the ink skipping around on the paper but it was better now it is saying to replace the black cartridge again i didn t print but pages before it told me to replace the cartridge my printer is years old and it is the biggest piece of s i ve ever owned i ll never ever buy another epson product not to mention the ink is stupid expensive you have to go somewhere like office max which is expensive in itself to buy the ink because walmart doesn t carry the product i would not recommend this product to anyone\n",
            "--------------------------------------------------------------------------------\n",
            "Average length (in characters) before preprocessing: 323.726712\n",
            "SAMPLE REVIEWS AFTER PREPROCESSING:\n",
            "Review 38683:\n",
            "light work tried replace battery entire pen basically fell apart hand biggest piece crap ever bought even working piece cheap cheap get yet still cost reason also first time return order amazon purchase\n",
            "--------------------------------------------------------------------------------\n",
            "Review 64939:\n",
            "let say front going try upload picture badge holder look great say three month routine use badge holder developed substantial crack central stress point longer functional clear design fundamentally flawed routine removing inserting one card approximately six time day course five day week result product failure less three month badge holder one lasted two year shame think significant population would willing shell extra cash durable dependable product company upgraded quality plastic might winner hand recommend product broke much quickly non abusive routine use give two star however worked great worked\n",
            "--------------------------------------------------------------------------------\n",
            "Review 3954:\n",
            "printer print color one ink cartridge terrible problem printing skipping around even read read learned maintenence clean head printer option option selected clear however clean head today went office max spent ink box multi black black printer would print getting home cleaned head time still completely fix problem ink skipping around paper better saying replace black cartridge print page told replace cartridge printer year old biggest piece ever owned never ever buy another epson product mention ink stupid expensive go somewhere like office max expensive buy ink walmart carry product would recommend product anyone\n",
            "--------------------------------------------------------------------------------\n",
            "Average length (in characters) after preprocessing: 199.191456\n",
            "Average length (in characters) before preprocessing: 323.726712\n"
          ]
        }
      ],
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def preprocess_text(text):\n",
        "    tokens = text.split()\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
        "    processed_text = \" \".join(tokens)\n",
        "    return processed_text\n",
        "\n",
        "sample_indices = df_balanced.sample(3, random_state=42).index\n",
        "\n",
        "print(\"SAMPLE REVIEWS BEFORE PREPROCESSING:\")\n",
        "for idx in sample_indices:\n",
        "    print(f\"Review {idx}:\\n{df_balanced.loc[idx, 'Review']}\")\n",
        "    print(\"-\"*80)\n",
        "\n",
        "avg_length_before_preprocessing = df_balanced['Review'].apply(len).mean()\n",
        "print(\"Average length (in characters) before preprocessing:\", avg_length_before_preprocessing)\n",
        "\n",
        "df_balanced['Review'] = df_balanced['Review'].apply(preprocess_text)\n",
        "\n",
        "print(\"SAMPLE REVIEWS AFTER PREPROCESSING:\")\n",
        "for idx in sample_indices:\n",
        "    print(f\"Review {idx}:\\n{df_balanced.loc[idx, 'Review']}\")\n",
        "    print(\"-\"*80)\n",
        "\n",
        "avg_length_after_preprocessing = df_balanced['Review'].apply(len).mean()\n",
        "print(\"Average length (in characters) after preprocessing:\", avg_length_after_preprocessing)\n",
        "\n",
        "print(\"Average length (in characters) before preprocessing:\", avg_length_before_preprocessing)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "COQWU4s0BayE",
        "outputId": "5687f0fb-0803-4e63-c17a-6a3402f660d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Binary class distribution:\n",
            "Label\n",
            "0    100000\n",
            "1    100000\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "df_binary = df_balanced[df_balanced['Sentiment'].isin([1, 2])].copy()\n",
        "\n",
        "# Map sentiment: class 1 (positive) -> label 1, class 2 (negative) -> label 0\n",
        "df_binary['Label'] = df_binary['Sentiment'].apply(lambda x: 1 if x == 1 else 0)\n",
        "\n",
        "print(\"Binary class distribution:\")\n",
        "print(df_binary['Label'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pi-gOZBxBayE"
      },
      "source": [
        "# STEP 2 OF HW-2:PART-B:  \n",
        "We make use of nltk package (previously seen on HW-1), to implement tokenization process. nltk.download('punkt') is used for word tokenization. We had to use nltk.download('punkt_tab') to run this code due to unexpected error with using just \"punkt\".   \n",
        "Step 1: Tokenize the input text using NLTK word_tokenize, convert to lowercase, remove non-alphabetic tokens. This is done using the function tokenize(text).    \n",
        "Step 2: Create 'sentences' from df_balanced. Already exists from part 1. df_balanced has columns ['Review', 'Rating', 'Sentiment']. Create a Word2Vec model with desired params: 1.vector_size=300 (given); window=11 (given); min_count=10 (ignore words appearing <10 times) workers=12 (I have a 16 core CPU, hence I have used 12).     \n",
        "We will then build the vocabulary from tokenized sentences. model_own.train() trains my model. To get a better result, I have done 7 epochs and extracted the trained word vectors.  Step 4: heck Semantic Similarities. I have started with the previously used example here as well and then compared it.    \n",
        "\n",
        "The answers to asked question:   \n",
        "Q1. What do you conclude from comparing vectors generated by yourself and the pretrained model?    \n",
        "A1. When comparing the pretrained Google News Word2Vec model with a Word2Vec model trained on our own Amazon reviews dataset, we observe some clear differences in the way each model captures and encodes semantic similarities.   Pretrained Model:   \n",
        "Trained on a massive, general-purpose corpus (Google News), encompassing a wide variety of everyday topics and vocabulary.     \n",
        "Consequently, it has extensive coverage of general English words, historical/political entities, cultural references, etc.    \n",
        "For words like “king,” “queen,” “woman,” and “man,” it has seen rich contextual usage, so it can correctly perform analogies like “king - man + woman → queen.”      \n",
        "\n",
        "Custom Model (Amazon Reviews):     \n",
        "Trained on domain-specific text (product reviews).      \n",
        "The corpus is skewed toward topics like product features, brand names, shipping, customer service, etc.     \n",
        "General or infrequent words like “king” or “queen” may appear rarely and thus do not develop strong semantic associations.      \n",
        "\n",
        "Domain-Specific Strengths:        \n",
        "\n",
        "While the pretrained model handles general English very well, it may not reflect how specific product terms and brand names are used in Amazon reviews.       \n",
        "The custom model, in contrast, can learn very precise relationships for frequently discussed items (e.g., “printer” ↔ “ink,” “paper” ↔ “quality,” etc.).      \n",
        "If you test words that occur commonly in the Amazon domain (e.g., “shipping,” “refund,” “receipt”), you may find that the custom model produces more coherent or contextually appropriate synonyms and neighbors.     \n",
        "\n",
        "\n",
        "Q2. Which of the Word2Vec models seems to encode semantic similarities between words better?        \n",
        "A2. For General English / Common Words: The pretrained Google News model is more likely to produce high-quality, intuitive analogies and similarity scores. It has seen a broader corpus, so it captures well-known linguistic relationships (like “king → queen,” “excellent → outstanding”).            \n",
        "For Domain-Specific Terms: The custom Amazon reviews model can outperform the pretrained model when dealing with specialized or product-centric vocabulary. If a term is very frequent in your dataset (e.g., “laptop,” “battery,” “warranty”), the custom embeddings might capture nuances that the general model misses.      \n",
        "\n",
        "CONCLUSION:     \n",
        "\n",
        "Pretrained Word2Vec (Google News) is generally stronger at broad, standard semantic relationships, especially for words that are common in general discourse.         \n",
        "Custom Word2Vec is more tailored to the Amazon reviews domain and can excel at capturing domain-specific semantics, but it lacks coverage of rarer general words or contexts not present in the review corpus.      \n",
        "\n",
        "# This brings an end to our STEP-2 PART-B.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZlTsdIxBayE",
        "outputId": "4891f1c6-76c7-4084-f036-5eb9a51734cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Binary class distribution:\n",
            "Label\n",
            "0    100000\n",
            "1    100000\n",
            "Name: count, dtype: int64\n",
            "Tokenizing all reviews\n",
            "Completed.\n",
            "Number of documents (reviews): 200000\n",
            "Vocabulary size: 12862 words\n",
            "Training Word2Vec on dataset..\n",
            "Training complete!\n",
            "\n",
            "=== Checking Analogy: king - man + woman ===\n",
            "latin: 0.5140\n",
            "men: 0.4750\n",
            "reproductive: 0.4612\n",
            "gender: 0.4575\n",
            "cancer: 0.4519\n",
            "\n",
            "=== Similarity: 'excellent' vs. 'outstanding' ===\n",
            "Similarity: 0.7871\n"
          ]
        }
      ],
      "source": [
        "def tokenize(text):\n",
        "\n",
        "    text = text.lower()\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    tokens = [t for t in tokens if t.isalpha()]\n",
        "\n",
        "    return tokens\n",
        "\n",
        "print(\"Binary class distribution:\")\n",
        "print(df_binary['Label'].value_counts())\n",
        "\n",
        "print(\"Tokenizing all reviews\")\n",
        "sentences = [tokenize(review) for review in df_binary['Review']]\n",
        "print(f\"Completed.\\nNumber of documents (reviews): {len(sentences)}\")\n",
        "\n",
        "\n",
        "model_own = Word2Vec(\n",
        "    vector_size=300,\n",
        "    window=11,\n",
        "    min_count=10,\n",
        "    workers=12\n",
        ")\n",
        "\n",
        "model_own.build_vocab(sentences)\n",
        "print(f\"Vocabulary size: {len(model_own.wv.key_to_index)} words\")\n",
        "\n",
        "print(\"Training Word2Vec on dataset..\")\n",
        "model_own.train(\n",
        "    sentences,\n",
        "    total_examples=model_own.corpus_count,\n",
        "    epochs=7\n",
        ")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "word_vectors_own = model_own.wv\n",
        "\n",
        "\n",
        "print(\"\\n=== Checking Analogy: king - man + woman ===\")\n",
        "try:\n",
        "    analogy_result = word_vectors_own.most_similar(\n",
        "        positive=['king', 'woman'],\n",
        "        negative=['man'],\n",
        "        topn=5\n",
        "    )\n",
        "    for word, similarity in analogy_result:\n",
        "        print(f\"{word}: {similarity:.4f}\")\n",
        "except KeyError as e:\n",
        "    print(f\"Word not in vocabulary: {e}\")\n",
        "\n",
        "print(\"\\n=== Similarity: 'excellent' vs. 'outstanding' ===\")\n",
        "try:\n",
        "    sim_score = word_vectors_own.similarity('excellent', 'outstanding')\n",
        "    print(f\"Similarity: {sim_score:.4f}\")\n",
        "except KeyError as e:\n",
        "    print(f\"Word not in vocabulary: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEdn6y_kBayE"
      },
      "source": [
        "# SIMPLE MODELS (STEP-3)           \n",
        "Having imported libraries already (see above), we will follow the pdf to achieve the step by step process to achieve the required model.     \n",
        "1. As mentioned previously, Data cleaning, Pre-processing and filtering into a binary class has been completed in previous steps. We will now continue with creating average word2vec vector computation.     \n",
        "This code executes the average word vector for a given text using a given Word2Vec model. Uses NLTK's word_tokenize to split text and filters to alphabetic tokens. Returns a zero vector if no tokens are found in the model's vocabulary.     \n",
        "We then compute average embeddings for each review. for both pre-trained and custom word2, new columns are created with the avg. vector.\n",
        "\n",
        "We will also do 'AvgPretrained' for df_balanced (FUTURE PURPOSE in step-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "51T_sOQqBayF"
      },
      "outputs": [],
      "source": [
        "def average_word_vector(text, model, vector_size=300):\n",
        "\n",
        "    tokens = nltk.word_tokenize(text.lower())\n",
        "\n",
        "    tokens = [t for t in tokens if t.isalpha()]\n",
        "\n",
        "    valid_vectors = []\n",
        "    for token in tokens:\n",
        "        if token in model.key_to_index:\n",
        "            valid_vectors.append(model[token])\n",
        "\n",
        "    if len(valid_vectors) == 0:\n",
        "        return np.zeros(vector_size)\n",
        "\n",
        "    return np.mean(valid_vectors, axis=0)\n",
        "\n",
        "df_binary['AvgPretrained'] = df_binary['Review'].apply(lambda x: average_word_vector(x, wv))\n",
        "df_binary['AvgCustom'] = df_binary['Review'].apply(lambda x: average_word_vector(x, model_own.wv))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def average_word_vector(text, model, vector_size=300):\n",
        "    tokens = nltk.word_tokenize(text.lower())\n",
        "    tokens = [token for token in tokens if token.isalpha()]\n",
        "\n",
        "    vectors = [model[token] for token in tokens if token in model.key_to_index]\n",
        "\n",
        "    if not vectors:\n",
        "        return np.zeros(vector_size)\n",
        "\n",
        "    return np.mean(vectors, axis=0)\n",
        "\n",
        "df_balanced['AvgPretrained'] = df_balanced['Review'].apply(lambda x: average_word_vector(x, wv))\n",
        "print(df_balanced[['Review', 'AvgPretrained']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBTfixz3dAo1",
        "outputId": "9834247d-65df-4706-95bd-51db1a2857e4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              Review  \\\n",
            "0  purchased tab whim put movie poster used four ...   \n",
            "1               returned much garbage involved setup   \n",
            "2  upholstered living room chair particularly big...   \n",
            "3                                              trash   \n",
            "4  hate printer without warning get error message...   \n",
            "\n",
            "                                       AvgPretrained  \n",
            "0  [0.04835728, 0.02457973, 0.009993689, 0.135595...  \n",
            "1  [0.11796875, 0.13583985, -0.06367187, 0.091650...  \n",
            "2  [0.034998577, 0.045771282, 0.032447178, 0.1003...  \n",
            "3  [0.024780273, 0.38476562, 0.092285156, 0.20605...  \n",
            "4  [0.0443637, 0.0371015, -0.03636071, 0.09358855...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIzbTMUgBayF"
      },
      "source": [
        "Now, we will re-use our TF-IDF (FEATURE EXTRACTION) steps made in HW-1 (As mentioned in pdf). The following code block executes that very same."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EFXHj2K4BayF",
        "outputId": "86a1b661-e6ef-4bbf-ef9c-74ff91dcb4b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (160000, 192491)\n",
            "X_test shape : (40000, 192491)\n",
            "y_train shape: (160000,)\n",
            "y_test shape : (40000,)\n"
          ]
        }
      ],
      "source": [
        "vectorizer = TfidfVectorizer(\n",
        "    ngram_range=(1, 2),\n",
        "    min_df=5,\n",
        "    max_df=0.8,\n",
        "    sublinear_tf=True\n",
        ")\n",
        "\n",
        "X = vectorizer.fit_transform(df_binary['Review'])\n",
        "y = df_binary['Sentiment'].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_test shape :\", X_test.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_test shape :\", y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kVwfrkNBayF"
      },
      "source": [
        "In this step, we will be creating matrices for word2vec representations bt stacking the average vectors into a 2D matrix.     \n",
        "And then, we will extract the binary labels.(1 = positive; 0 = negative)        \n",
        "\n",
        "For a pre-trained word2vec, each row is a 300-Dim vector."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Z8Zq9b_VBayF"
      },
      "outputs": [],
      "source": [
        "X_pretrained = np.vstack(df_binary['AvgPretrained'].values)\n",
        "X_custom = np.vstack(df_binary['AvgCustom'].values)\n",
        "\n",
        "y = df_binary['Label'].values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-0WnoJyBayF"
      },
      "source": [
        "Now, we will execute the train-test split. This will be an 80-20 split (respectively, as mentioned in the pdf)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "XEID6BZnBayF"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# For pretrained Word2Vec features\n",
        "X_train_pre, X_test_pre, _, _ = train_test_split(\n",
        "    X_pretrained, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# For custom Word2Vec features\n",
        "X_train_custom, X_test_custom, _, _ = train_test_split(\n",
        "    X_custom, y, test_size=0.2, random_state=42, stratify=y\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npEPd0fRBayF"
      },
      "source": [
        "Now, we will train classifiers and evaluate them. As mentioned in the pdf, it will the perceptron and SVM.     \n",
        "For each feature type, we train a Perceptron and an SVM model, then report testing accuracy.      \n",
        "       \n",
        "The first code blovk will implement perceptron. (Below!)       "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "ClYQh4mPBayF"
      },
      "outputs": [],
      "source": [
        "perc_tfidf = Perceptron(random_state=42)\n",
        "perc_tfidf.fit(X_train, y_train)\n",
        "acc_tfidf_perc = accuracy_score(y_test, perc_tfidf.predict(X_test))\n",
        "\n",
        "# Perceptron using pretrained Word2Vec features\n",
        "perc_pre = Perceptron(random_state=42)\n",
        "perc_pre.fit(X_train_pre, y_train)\n",
        "acc_pre_perc = accuracy_score(y_test, perc_pre.predict(X_test_pre))\n",
        "\n",
        "# Similarly, for the custom Word2Vec features:\n",
        "perc_custom = Perceptron(random_state=42)\n",
        "perc_custom.fit(X_train_custom, y_train)\n",
        "acc_custom_perc = accuracy_score(y_test, perc_custom.predict(X_test_custom))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amP6lIXyBayG"
      },
      "source": [
        "The below code block will implement Linear SVM. As SVM took more than 55 minutes to run!!! (TWICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "ku5BnkypBayG"
      },
      "outputs": [],
      "source": [
        "linear_svc_tfidf = LinearSVC(random_state=42, max_iter=10000)\n",
        "linear_svc_tfidf.fit(X_train, y_train)\n",
        "acc_tfidf_linear = accuracy_score(y_test, linear_svc_tfidf.predict(X_test))\n",
        "\n",
        "# LinearSVC using pretrained Word2Vec features\n",
        "linear_svc_pre = LinearSVC(random_state=42, max_iter=10000)\n",
        "linear_svc_pre.fit(X_train_pre, y_train)\n",
        "acc_pre_linear = accuracy_score(y_test, linear_svc_pre.predict(X_test_pre))\n",
        "\n",
        "# LinearSVC using custom Word2Vec features\n",
        "linear_svc_custom = LinearSVC(random_state=42, max_iter=10000)\n",
        "linear_svc_custom.fit(X_train_custom, y_train)\n",
        "acc_custom_linear = accuracy_score(y_test, linear_svc_custom.predict(X_test_custom))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uU2LnAMuBayG"
      },
      "source": [
        "The following code block PRINTS the desired values as the computation is now complete. This brings an end to the STEP-3 of our homework."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OD2TGLe_BayG",
        "outputId": "cca2966f-0da7-4e40-de7b-fd0aa7dd1ca7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Perceptron Testing Accuracy:\n",
            "TF-IDF: 0.850075\n",
            "Pretrained Word2Vec: 0.762025\n",
            "Custom Word2Vec: 0.7682\n",
            "\n",
            "SVM Testing Accuracy:\n",
            "TF-IDF: 0.8833\n",
            "Pretrained Word2Vec: 0.817425\n",
            "Custom Word2Vec: 0.8433\n"
          ]
        }
      ],
      "source": [
        "print(\"Perceptron Testing Accuracy:\")\n",
        "print(\"TF-IDF:\", acc_tfidf_perc)\n",
        "print(\"Pretrained Word2Vec:\", acc_pre_perc)\n",
        "print(\"Custom Word2Vec:\", acc_custom_perc)\n",
        "\n",
        "print(\"\\nSVM Testing Accuracy:\")\n",
        "print(\"TF-IDF:\", acc_tfidf_linear)\n",
        "print(\"Pretrained Word2Vec:\", acc_pre_linear)\n",
        "print(\"Custom Word2Vec:\", acc_custom_linear)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwWwQaCABayG"
      },
      "source": [
        "# QUESTION BASED ON STEP-3 FROM PDF:        \n",
        "\n",
        "Q1. What do you conclude from comparing performances for the models trained using the three different feature types (TF-IDF, pretrained Word2Vec, your trained Word2Vec)?     \n",
        "A1.          \n",
        "TF-IDF Features Are Most Effective:       \n",
        "Both the Perceptron and SVM classifiers achieved the highest testing accuracies when using TF-IDF features (approximately 85.0% for Perceptron and 88.3% for SVM).        \n",
        "This suggests that the sparse, high-dimensional representation from TF-IDF—which directly captures word frequency and discriminative terms—provides strong signals for sentiment classification on this dataset.      \n",
        "\n",
        "Pretrained Word2Vec Features (Google News):           \n",
        "The classifiers using pretrained Word2Vec embeddings performed moderately well, but they consistently lagged behind the TF-IDF baseline (about 76.2% with Perceptron and 81.7% with SVM).\n",
        "One reason for this could be that the Google News model is trained on a very general corpus. While it captures broad semantic relationships, it might not be as finely tuned to the domain-specific vocabulary and context found in Amazon reviews.                 \n",
        "\n",
        "Custom Word2Vec Features (Trained on Amazon Reviews):           \n",
        "The custom Word2Vec model, trained directly on the Amazon reviews, shows slightly lower performance with the Perceptron (around 76.8%) but performs better with the SVM (approximately 84.3%), though still not matching TF-IDF.\n",
        "This indicates that while the domain-specific embeddings capture nuances of the review language, they might require further tuning (e.g., more training data, hyperparameter adjustments) to reach the discriminative power of TF-IDF.\n",
        "It also suggests that the linear classifier (SVM) is better at leveraging the semantic information contained in these lower-dimensional embeddings compared to the Perceptron.         \n",
        "\n",
        "Classifier Differences:            \n",
        "Across all feature types, the SVM (or LinearSVC) models outperformed the Perceptron models. This is not unusual in high-dimensional text classification tasks, as SVMs typically handle sparse and high-dimensional data more robustly.     \n",
        "\n",
        "Overall Conclusion:        \n",
        "For this sentiment classification task on Amazon reviews:        \n",
        "\n",
        "TF-IDF stands out as the strongest feature representation, likely because it directly leverages term frequencies and emphasizes discriminative words.               \n",
        "Pretrained Word2Vec offers moderate performance but may not capture domain-specific subtleties as well as TF-IDF.              \n",
        "Custom Word2Vec embeddings, although tailored to the domain, still trail behind TF-IDF—suggesting that further refinement or combination with other features might be necessary to improve performance.          \n",
        "\n",
        "# WITH THIS, WE COMPLETE STEP-3         "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6VgjDsMBayG"
      },
      "source": [
        "# STEP-4: FEED FORWARD NEURAL NETWORKS       \n",
        "part (a)\n",
        "\n",
        "We have switched to Colab now, as we tried to upgrade pytorch, which made numpy upgrade and failed our gensim, after a day long session of debugging, costed our kernel to DIE!!\n",
        "\n",
        "So we will be using CPU to compute this neural network, as I cannot pay $10 for colab subscription.\n",
        "\n",
        "Anyway, the following code converts our numpy arrays to torch tensors and move them to the selected device (CPU in this case) I am following this method so that I can try to fix my CUDA and run on GPU later!\n",
        "\n",
        "Following the requirements of the pdf, we will slit the dataset, and print the values.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LyuQPFAEBayG",
        "outputId": "c8f3e669-b40d-47de-eab3-6ec6dd06fced"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "X_train_avg shape: (160000, 300)\n",
            "X_test_avg shape : (40000, 300)\n",
            "y_train shape: (160000,)\n",
            "y_test shape : (40000,)\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "X_pretrained = np.vstack(df_binary['AvgPretrained'].values)\n",
        "y = df_binary['Label'].values\n",
        "\n",
        "X_train_avg, X_test_avg, y_train, y_test = train_test_split(\n",
        "    X_pretrained, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(\"X_train_avg shape:\", X_train_avg.shape)\n",
        "print(\"X_test_avg shape :\", X_test_avg.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_test shape :\", y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we will Convert Data to PyTorch Tensors and Create DataLoaders"
      ],
      "metadata": {
        "id": "nn8ws8JoWiG5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tensor = torch.from_numpy(X_train_avg).float().to(device)\n",
        "y_train_tensor = torch.from_numpy(y_train).long().to(device)\n",
        "X_test_tensor = torch.from_numpy(X_test_avg).float().to(device)\n",
        "y_test_tensor = torch.from_numpy(y_test).long().to(device)\n",
        "\n",
        "batch_size = 64\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "bI--du92WmIH"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Now, we will define and execute the MLP model**"
      ],
      "metadata": {
        "id": "66J8A0HsW5ig"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_dim, hidden1, hidden2, output_dim):\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden1)\n",
        "        self.fc2 = nn.Linear(hidden1, hidden2)\n",
        "        self.fc3 = nn.Linear(hidden2, output_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "input_dim = 300   # Average Word2Vec vector dimension\n",
        "hidden1 = 50\n",
        "hidden2 = 10\n",
        "output_dim = 2    # For binary classification: 2 classes\n",
        "\n",
        "model = MLP(input_dim, hidden1, hidden2, output_dim).to(device)"
      ],
      "metadata": {
        "id": "OiUWRBQ6XHiE"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we will define loss function and optimizer, and then follow up with a training loop"
      ],
      "metadata": {
        "id": "j06aTe8HXPtC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "num_epochs = 10\n",
        "model.train()\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    for batch_X, batch_y in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(batch_X)\n",
        "        loss = criterion(outputs, batch_y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * batch_X.size(0)\n",
        "    epoch_loss = running_loss / len(train_dataset)\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FcLF4ebpXX_s",
        "outputId": "5af41a37-fe82-487c-bd53-f36f5f461e59"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.4209\n",
            "Epoch [2/10], Loss: 0.3810\n",
            "Epoch [3/10], Loss: 0.3690\n",
            "Epoch [4/10], Loss: 0.3613\n",
            "Epoch [5/10], Loss: 0.3547\n",
            "Epoch [6/10], Loss: 0.3496\n",
            "Epoch [7/10], Loss: 0.3448\n",
            "Epoch [8/10], Loss: 0.3402\n",
            "Epoch [9/10], Loss: 0.3370\n",
            "Epoch [10/10], Loss: 0.3333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, for the binary classification, we will evaluate on test dataset"
      ],
      "metadata": {
        "id": "RjxH64KEX_kh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "all_preds = []\n",
        "with torch.no_grad():\n",
        "    for batch_X, _ in test_loader:\n",
        "        outputs = model(batch_X)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        all_preds.append(preds)\n",
        "all_preds = torch.cat(all_preds).cpu().numpy()\n",
        "\n",
        "mlp_test_accuracy = accuracy_score(y_test, all_preds)\n",
        "print(\"MLP Testing Accuracy (Binary, Avg Word2Vec features):\", mlp_test_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwbsZVZDYI_c",
        "outputId": "84bc1d65-a1c6-40a7-e116-5cba1e70f6f4"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP Testing Accuracy (Binary, Avg Word2Vec features): 0.84435\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **now, let's do this all over again for the ternary dataset preparation, execution and testing!!!**"
      ],
      "metadata": {
        "id": "O2yREAV2ZJUo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_balanced['Label_Ternary'] = df_balanced['Sentiment'] - 1\n",
        "\n",
        "# Debug: Print unique labels to confirm\n",
        "print(\"Unique ternary labels:\", df_balanced['Label_Ternary'].unique())\n",
        "\n",
        "\n",
        "X_avg = np.vstack(df_balanced['AvgPretrained'].values)\n",
        "y_ternary = df_balanced['Label_Ternary'].values         # Should have values 0,1,2\n",
        "\n",
        "\n",
        "X_train_avg, X_test_avg, y_train, y_test = train_test_split(\n",
        "    X_avg, y_ternary, test_size=0.2, random_state=42, stratify=y_ternary\n",
        ")\n",
        "\n",
        "print(\"X_train_avg shape:\", X_train_avg.shape)\n",
        "print(\"X_test_avg shape :\", X_test_avg.shape)\n",
        "print(\"y_train unique labels:\", np.unique(y_train))\n",
        "print(\"y_test unique labels:\", np.unique(y_test))\n",
        "\n",
        "\n",
        "X_train_tensor = torch.from_numpy(X_train_avg).float().to(device)\n",
        "y_train_tensor = torch.from_numpy(y_train).long().to(device)\n",
        "X_test_tensor = torch.from_numpy(X_test_avg).float().to(device)\n",
        "y_test_tensor = torch.from_numpy(y_test).long().to(device)\n",
        "\n",
        "batch_size = 64\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_dim, hidden1, hidden2, output_dim):\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden1)\n",
        "        self.fc2 = nn.Linear(hidden1, hidden2)\n",
        "        self.fc3 = nn.Linear(hidden2, output_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "input_dim = 300\n",
        "hidden1 = 50\n",
        "hidden2 = 10\n",
        "output_dim = 3    # For ternary classification: 3 classes (0,1,2).\n",
        "\n",
        "model = MLP(input_dim, hidden1, hidden2, output_dim).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "num_epochs = 10\n",
        "model.train()\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    for batch_X, batch_y in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(batch_X)\n",
        "        loss = criterion(outputs, batch_y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * batch_X.size(0)\n",
        "    epoch_loss = running_loss / len(train_dataset)\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}\")\n",
        "\n",
        "model.eval()\n",
        "all_preds = []\n",
        "with torch.no_grad():\n",
        "    for batch_X, _ in test_loader:\n",
        "        outputs = model(batch_X)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        all_preds.append(preds)\n",
        "all_preds = torch.cat(all_preds).cpu().numpy()\n",
        "\n",
        "mlp_test_accuracy = accuracy_score(y_test, all_preds)\n",
        "print(\"MLP Testing Accuracy (Ternary, Avg Word2Vec features):\", mlp_test_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50AKNntjZTMW",
        "outputId": "df96028a-1f5d-45e2-c299-08e35ea6f4ee"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique ternary labels: [1 2 0]\n",
            "X_train_avg shape: (200000, 300)\n",
            "X_test_avg shape : (50000, 300)\n",
            "y_train unique labels: [0 1 2]\n",
            "y_test unique labels: [0 1 2]\n",
            "Epoch [1/10], Loss: 0.8018\n",
            "Epoch [2/10], Loss: 0.7596\n",
            "Epoch [3/10], Loss: 0.7479\n",
            "Epoch [4/10], Loss: 0.7392\n",
            "Epoch [5/10], Loss: 0.7331\n",
            "Epoch [6/10], Loss: 0.7278\n",
            "Epoch [7/10], Loss: 0.7239\n",
            "Epoch [8/10], Loss: 0.7202\n",
            "Epoch [9/10], Loss: 0.7168\n",
            "Epoch [10/10], Loss: 0.7140\n",
            "MLP Testing Accuracy (Ternary, Avg Word2Vec features): 0.68232\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Now, we move on to PART (B) of STEP-4**        \n",
        "We will now define a function to get concatenated Word2Vec feature     \n",
        "This tokenizes the text using NLTK, keeps only alphabetic tokens, selects the first max_tokens tokens, retrieves their word vectors from 'model', and concatenates them into a single vector. Then returns a 1D numpy array of length max_tokens.\n"
      ],
      "metadata": {
        "id": "_bmg4CTZhPUY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_concatenated_vector(text, model, vector_size=300, max_tokens=10):\n",
        "\n",
        "    tokens = nltk.word_tokenize(text.lower())\n",
        "    # Keep only alphabetic tokens\n",
        "    tokens = [token for token in tokens if token.isalpha()]\n",
        "\n",
        "    vectors = []\n",
        "    for token in tokens[:max_tokens]:\n",
        "        if token in model.key_to_index:\n",
        "            vectors.append(model[token])\n",
        "        else:\n",
        "            vectors.append(np.zeros(vector_size))\n",
        "    while len(vectors) < max_tokens:\n",
        "        vectors.append(np.zeros(vector_size))\n",
        "\n",
        "    # Concatenate all vectors to form a single 1D array\n",
        "    return np.concatenate(vectors)\n"
      ],
      "metadata": {
        "id": "syTj-n9Whmb9"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will now compute concatenated featured for each review in the binary dataset. We then prepare feature matrix and labels for binary classification, with debug statements (of course), and split the dataset into training and testing."
      ],
      "metadata": {
        "id": "M_Jsa4PximPZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_binary['ConcatPretrained'] = df_binary['Review'].apply(lambda x: get_concatenated_vector(x, wv))\n",
        "\n",
        "X_concat = np.vstack(df_binary['ConcatPretrained'].values)\n",
        "y = df_binary['Label'].values\n",
        "\n",
        "print(\"X_concat shape:\", X_concat.shape)\n",
        "print(\"Unique labels:\", np.unique(y))\n",
        "\n",
        "X_train_concat, X_test_concat, y_train, y_test = train_test_split(\n",
        "    X_concat, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(\"X_train_concat shape:\", X_train_concat.shape)\n",
        "print(\"X_test_concat shape :\", X_test_concat.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_test shape :\", y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1poLNmJiniS",
        "outputId": "ed39b6dc-90f5-4695-94f8-b9ffa30e8501"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_concat shape: (200000, 3000)\n",
            "Unique labels: [0 1]\n",
            "X_train_concat shape: (160000, 3000)\n",
            "X_test_concat shape : (40000, 3000)\n",
            "y_train shape: (160000,)\n",
            "y_test shape : (40000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this next step, we will we will convert data to PyTorch tensors and create dataloaders"
      ],
      "metadata": {
        "id": "wK9YaRHNHxJw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tensor = torch.from_numpy(X_train_concat).float().to(device)\n",
        "y_train_tensor = torch.from_numpy(y_train).long().to(device)\n",
        "X_test_tensor = torch.from_numpy(X_test_concat).float().to(device)\n",
        "y_test_tensor = torch.from_numpy(y_test).long().to(device)\n",
        "\n",
        "batch_size = 64\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "iUwxRuUYIdMg"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we will define the MLP model for binary classification"
      ],
      "metadata": {
        "id": "0sidQVK4IhUw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_dim, hidden1, hidden2, output_dim):\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden1)\n",
        "        self.fc2 = nn.Linear(hidden1, hidden2)\n",
        "        self.fc3 = nn.Linear(hidden2, output_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "input_dim = 3000\n",
        "hidden1 = 50\n",
        "hidden2 = 10\n",
        "output_dim = 2\n",
        "\n",
        "model = MLP(input_dim, hidden1, hidden2, output_dim).to(device)"
      ],
      "metadata": {
        "id": "dRS7sHk9Iq_I"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will now define loss function and optimizer, then create a training loop"
      ],
      "metadata": {
        "id": "TCEWlrEbIzBN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "num_epochs = 10\n",
        "model.train()\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    for batch_X, batch_y in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(batch_X)\n",
        "        loss = criterion(outputs, batch_y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * batch_X.size(0)\n",
        "    epoch_loss = running_loss / len(train_dataset)\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o3VyA0CdI-LV",
        "outputId": "6b341d61-86a5-4058-dd29-6b7f922bb4a9"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.4833\n",
            "Epoch [2/10], Loss: 0.4309\n",
            "Epoch [3/10], Loss: 0.3902\n",
            "Epoch [4/10], Loss: 0.3485\n",
            "Epoch [5/10], Loss: 0.3049\n",
            "Epoch [6/10], Loss: 0.2648\n",
            "Epoch [7/10], Loss: 0.2295\n",
            "Epoch [8/10], Loss: 0.1980\n",
            "Epoch [9/10], Loss: 0.1714\n",
            "Epoch [10/10], Loss: 0.1513\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we will now evaluate on the test set, get the test dataset accuracy for comparison."
      ],
      "metadata": {
        "id": "W7r4fP0AJtg6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "all_preds = []\n",
        "with torch.no_grad():\n",
        "    for batch_X, _ in test_loader:\n",
        "        outputs = model(batch_X)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        all_preds.append(preds)\n",
        "all_preds = torch.cat(all_preds).cpu().numpy()\n",
        "\n",
        "mlp_test_accuracy = accuracy_score(y_test, all_preds)\n",
        "print(\"MLP Testing Accuracy (Binary, Concat Pretrained Word2Vec features):\", mlp_test_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbsZwWKtJ4bq",
        "outputId": "0ab7a135-2ea1-4e30-c329-1672a8fa6a65"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP Testing Accuracy (Binary, Concat Pretrained Word2Vec features): 0.752975\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "With this, we now complete STEP-4 part (a) and part (b), displaying necessary (pdf required) results.     \n",
        "    \n",
        "#**MLP Testing Accuracy: 0.68576**         \n",
        "#**MLP Testing Accuracy: 0.746825**      \n",
        "\n",
        "**QUESTIONS BASED ON STEP-4:**       \n",
        "\n",
        "Q1. What do you conclude by comparing accuracy values you obtain with those obtained in the Simple Models section (note you can compare the accuracy values for binary classification).        \n",
        "A1.    \n",
        "Simple Models (from Step 3):\n",
        "\n",
        "Simple models using TF-IDF features (with Perceptron and SVM) achieved testing accuracies in the range of approximately 85%–88%.      \n",
        "This indicates that TF-IDF—a high-dimensional, sparse representation capturing word frequency and importance—is very effective for binary sentiment classification in the dataset.      \n",
        "\n",
        "\n",
        "MLP with Word2Vec Features (Step 4):\n",
        "\n",
        "When using the average Word2Vec vectors as input, your MLP achieved a testing accuracy of about 68.6%.\n",
        "When using the concatenation of the first 10 Word2Vec vectors (resulting in a 3000-dimensional input), the MLP improved to about 74.7% testing accuracy.\n",
        "This shows that concatenating the vectors (thus preserving some order and token-level detail) gives better results than simply averaging—but both methods still underperform compared to the TF-IDF baseline.        \n",
        "\n",
        "\n",
        "\n",
        "Conclusions from the Comparison:\n",
        "\n",
        "TF-IDF features provide very strong performance for this task, likely because they capture explicit term frequency patterns and discriminative vocabulary, which are highly relevant for sentiment analysis.         \n",
        "Word2Vec embeddings, while they capture semantic relationships, seem to lose some discriminative detail when combined using simple averaging. Concatenation helps to preserve more context and improves performance, but even then, the MLP doesn't match the accuracy obtained by TF-IDF-based simple models.       \n",
        "\n",
        "# **END OF STEP-4**"
      ],
      "metadata": {
        "id": "MFcsM3SYKD40"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **STEP-5**      \n",
        "\n",
        "Sentiment classification using the word embedding (executed previously in step-2)     \n",
        "In this step, we will be converting to lower case and keeping only alpha tokens."
      ],
      "metadata": {
        "id": "pXqqCyFKSoUy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def review_to_fixed_vectors(text, model, max_length=50, vector_size=300):\n",
        "    tokens = nltk.word_tokenize(text.lower())\n",
        "    tokens = [t for t in tokens if t.isalpha()]\n",
        "\n",
        "    vectors = []\n",
        "\n",
        "    for token in tokens[:max_length]:\n",
        "        if token in model.key_to_index:\n",
        "            vectors.append(model[token])\n",
        "        else:\n",
        "            vectors.append(np.zeros(vector_size))\n",
        "\n",
        "    while len(vectors) < max_length:\n",
        "        vectors.append(np.zeros(vector_size))\n",
        "\n",
        "    return np.stack(vectors)"
      ],
      "metadata": {
        "id": "Y_GlXQ1mW6ZM"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From previous df_binary dataframe usage, we check if there exists a column: 'Review' and 'label' and we verify the status as well.     \n",
        "We then move on to creating and executing the feature matrix and labels for CNN training."
      ],
      "metadata": {
        "id": "vc39glYsXWKX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_subset = df_binary.sample(n=50000, random_state=42).copy()\n",
        "\n",
        "df_subset['FixedVectors'] = df_binary['Review'].apply(lambda x: review_to_fixed_vectors(x, wv, max_length=50, vector_size=300).astype(np.float32))\n",
        "print(\"Shape of fixed vector for one review:\", df_subset['FixedVectors'].iloc[0].shape)\n",
        "\n",
        "X_fixed = np.stack(df_subset['FixedVectors'].values)\n",
        "y = df_subset['Label'].values\n",
        "\n",
        "X_fixed = X_fixed.reshape(X_fixed.shape[0], 1, 50, 300)\n",
        "print(\"X_fixed shape:\", X_fixed.shape)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_fixed, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_test shape :\", X_test.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_test shape :\", y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-9AVeUgXWxL",
        "outputId": "204b7cf4-f58f-4a77-bccc-a9f206fd1b86"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of fixed vector for one review: (50, 300)\n",
            "X_fixed shape: (50000, 1, 50, 300)\n",
            "X_train shape: (40000, 1, 50, 300)\n",
            "X_test shape : (10000, 1, 50, 300)\n",
            "y_train shape: (40000,)\n",
            "y_test shape : (10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will now convert data to Pytorch tensors and create dataloaders (what we have seen previously)"
      ],
      "metadata": {
        "id": "Mo6Vv_f--SDD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "X_train_tensor = torch.from_numpy(X_train).float().to(device)\n",
        "y_train_tensor = torch.from_numpy(y_train).long().to(device)\n",
        "X_test_tensor = torch.from_numpy(X_test).float().to(device)\n",
        "y_test_tensor = torch.from_numpy(y_test).long().to(device)\n",
        "\n",
        "batch_size = 64\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7UI2CaUgwpa",
        "outputId": "a4f17088-ce06-431d-c85a-be7ef2a9dc26"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this cide, we define the CNN for binary classification. We use a 2D CNN that processes the input of shape. Finally, we flatten and use a fully-connected layer to produce 2 outputs."
      ],
      "metadata": {
        "id": "JDo_17kV-eoo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TextCNN(nn.Module):\n",
        "    def __init__(self, input_dim, max_length, output_dim):\n",
        "        super(TextCNN, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=50, kernel_size=(3, input_dim), padding=(1,0))\n",
        "        self.conv2 = nn.Conv2d(in_channels=50, out_channels=10, kernel_size=(3,1), padding=(1,0))\n",
        "\n",
        "        self.fc = nn.Linear(10 * max_length, output_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = self.relu(self.conv2(x))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "input_dim = 300\n",
        "max_length = 50\n",
        "output_dim = 2\n",
        "\n",
        "model = TextCNN(input_dim, max_length, output_dim).to(device)"
      ],
      "metadata": {
        "id": "8H-YqLjzg1SF"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we define loss function and entropy (also initialize it), and start the training loop."
      ],
      "metadata": {
        "id": "GzS_t6aA-wqp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "num_epochs = 10\n",
        "model.train()\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    for batch_X, batch_y in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(batch_X)\n",
        "        loss = criterion(outputs, batch_y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * batch_X.size(0)\n",
        "    epoch_loss = running_loss / len(train_dataset)\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aM6K7J1dg8vv",
        "outputId": "cc91721e-5d99-4b99-ce1c-ca5dbaae59cc"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.4434\n",
            "Epoch [2/10], Loss: 0.3817\n",
            "Epoch [3/10], Loss: 0.3446\n",
            "Epoch [4/10], Loss: 0.3188\n",
            "Epoch [5/10], Loss: 0.2946\n",
            "Epoch [6/10], Loss: 0.2739\n",
            "Epoch [7/10], Loss: 0.2469\n",
            "Epoch [8/10], Loss: 0.2211\n",
            "Epoch [9/10], Loss: 0.2002\n",
            "Epoch [10/10], Loss: 0.1778\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we evaluate CNN on the test set, and fetch results accordingly."
      ],
      "metadata": {
        "id": "kVlf6QVu-7C6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "all_preds = []\n",
        "with torch.no_grad():\n",
        "    for batch_X, _ in test_loader:\n",
        "        outputs = model(batch_X)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        all_preds.append(preds)\n",
        "all_preds = torch.cat(all_preds).cpu().numpy()\n",
        "\n",
        "cnn_test_accuracy = accuracy_score(y_test, all_preds)\n",
        "print(\"CNN Testing Accuracy (Binary, Concat Word2Vec features):\", cnn_test_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0Xl0TSFhIXk",
        "outputId": "17ebfa70-0992-4c49-a207-1d6676ec314e"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN Testing Accuracy (Binary, Concat Word2Vec features): 0.8354\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Here starts the code for TERNARY classification**       \n",
        "Below is the same process for what we did above( FOR BINARY, but we change certain aspects of what's required, such as 'output_dim = 3', and so on..."
      ],
      "metadata": {
        "id": "A_CHHGFY_IVy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def review_to_fixed_vectors(text, model, max_length=50, vector_size=300):\n",
        "\n",
        "    tokens = nltk.word_tokenize(text.lower())\n",
        "    tokens = [t for t in tokens if t.isalpha()]\n",
        "\n",
        "    vectors = []\n",
        "    for token in tokens[:max_length]:\n",
        "        if token in model.key_to_index:\n",
        "            vectors.append(model[token])\n",
        "        else:\n",
        "            vectors.append(np.zeros(vector_size))\n",
        "\n",
        "\n",
        "    while len(vectors) < max_length:\n",
        "        vectors.append(np.zeros(vector_size))\n",
        "\n",
        "    return np.stack(vectors)"
      ],
      "metadata": {
        "id": "VcYZR_6khvX3"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_balanced['Label_Ternary'] = df_balanced['Sentiment'] - 1\n",
        "\n",
        "print(\"Unique ternary labels:\", df_balanced['Label_Ternary'].unique())\n",
        "\n",
        "df_subset = df_balanced.sample(n=50000, random_state=42).copy()\n",
        "df_subset['FixedVectors'] = df_subset['Review'].apply(lambda x: review_to_fixed_vectors(x, wv, max_length=50, vector_size=300).astype(np.float32))\n",
        "print(\"Shape of fixed vector for one review:\", df_subset['FixedVectors'].iloc[0].shape)\n",
        "\n",
        "X_fixed = np.stack(df_subset['FixedVectors'].values)\n",
        "y_ternary = df_subset['Label_Ternary'].values\n",
        "\n",
        "X_fixed = X_fixed.reshape(X_fixed.shape[0], 1, 50, 300)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_fixed, y_ternary, test_size=0.2, random_state=42, stratify=y_ternary\n",
        ")\n",
        "\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_test shape :\", X_test.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_test shape :\", y_test.shape)\n",
        "print(\"Unique labels in y_train:\", np.unique(y_train))\n",
        "print(\"Unique labels in y_test:\", np.unique(y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3S8srinh3Co",
        "outputId": "3bfffed5-ba5a-4521-ec2e-953b7e7da2e4"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique ternary labels: [1 2 0]\n",
            "Shape of fixed vector for one review: (50, 300)\n",
            "X_train shape: (40000, 1, 50, 300)\n",
            "X_test shape : (10000, 1, 50, 300)\n",
            "y_train shape: (40000,)\n",
            "y_test shape : (10000,)\n",
            "Unique labels in y_train: [0 1 2]\n",
            "Unique labels in y_test: [0 1 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "X_train_tensor = torch.from_numpy(X_train).float().to(device)\n",
        "y_train_tensor = torch.from_numpy(y_train).long().to(device)\n",
        "X_test_tensor = torch.from_numpy(X_test).float().to(device)\n",
        "y_test_tensor = torch.from_numpy(y_test).long().to(device)\n",
        "\n",
        "batch_size = 64\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSN31doFiFiz",
        "outputId": "44bf9510-be86-4c71-e2d7-67a8ff01d369"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TextCNN(nn.Module):\n",
        "    def __init__(self, input_dim, max_length, output_dim):\n",
        "        super(TextCNN, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=50, kernel_size=(3, input_dim), padding=(1,0))\n",
        "        self.conv2 = nn.Conv2d(in_channels=50, out_channels=10, kernel_size=(3,1), padding=(1,0))\n",
        "\n",
        "        self.fc = nn.Linear(10 * max_length, output_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = self.relu(self.conv2(x))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "T64fSwf9iJS6"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim = 300\n",
        "max_length = 50\n",
        "output_dim = 3\n",
        "\n",
        "model = TextCNN(input_dim, max_length, output_dim).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "num_epochs = 10\n",
        "model.train()\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    for batch_X, batch_y in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(batch_X)\n",
        "        loss = criterion(outputs, batch_y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * batch_X.size(0)\n",
        "    epoch_loss = running_loss / len(train_dataset)\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZZa_U5RiQLK",
        "outputId": "eae83232-ef92-4a3c-e64f-a23e2d84aec4"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.8652\n",
            "Epoch [2/10], Loss: 0.7760\n",
            "Epoch [3/10], Loss: 0.7379\n",
            "Epoch [4/10], Loss: 0.7031\n",
            "Epoch [5/10], Loss: 0.6737\n",
            "Epoch [6/10], Loss: 0.6489\n",
            "Epoch [7/10], Loss: 0.6204\n",
            "Epoch [8/10], Loss: 0.5954\n",
            "Epoch [9/10], Loss: 0.5714\n",
            "Epoch [10/10], Loss: 0.5396\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "all_preds = []\n",
        "with torch.no_grad():\n",
        "    for batch_X, _ in test_loader:\n",
        "        outputs = model(batch_X)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        all_preds.append(preds)\n",
        "all_preds = torch.cat(all_preds).cpu().numpy()\n",
        "\n",
        "cnn_test_accuracy = accuracy_score(y_test, all_preds)\n",
        "print(\"CNN Testing Accuracy (Ternary, Concat Word2Vec features):\", cnn_test_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0LytOiiciWUu",
        "outputId": "c9ed4964-fce0-4f6f-d372-fa44c4617fb6"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN Testing Accuracy (Ternary, Concat Word2Vec features): 0.6781\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see, the accuracy difference is not marginal.\n",
        "\n",
        "Accuracy of CNN in binary classification: 0.8354\n",
        "Accuracy of CNN in ternary classification: 0.6781\n",
        "\n",
        "Due to system RAM issues (run out of storage, I had to reduce the dataset cap to 50,000 and a 32bit int type. 😭🙏)          \n",
        "\n",
        "#**WITH THIS, ALL THE SCORES HAVE BEEN REPORTED AND THE HOMEWORK-2 COMES TO AN END**"
      ],
      "metadata": {
        "id": "WMs8V-atHS_R"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}